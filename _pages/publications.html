---
permalink: /
title: "Hello!!! Myself Mohammed Tawshif Hossain"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
  .project-container {
    display: flex;
    align-items: flex-start;
    justify-content: space-between;
    margin-bottom: 4em;
    gap: 30px;
    flex-wrap: wrap;
    padding: 2em;
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    border-radius: 16px;
    box-shadow: 0 8px 24px rgba(0,0,0,0.12);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
  }
  
  .project-container:hover {
    transform: translateY(-5px);
    box-shadow: 0 12px 32px rgba(0,0,0,0.18);
  }
  
  .project-text {
    flex: 1 1 70%;
    min-width: 300px;
    order: 1;
  }
  
  .project-text h4 {
    color: #2c3e50;
    font-size: 1.4em;
    margin-bottom: 0.8em;
    line-height: 1.4;
  }
  
  .project-text p {
    color: #34495e;
    line-height: 1.7;
    font-size: 1.05em;
    text-align: justify;
  }
  
  .project-image {
    flex: 0 0 25%;
    max-width: 250px;
    min-width: 200px;
    order: 2;
    align-self: center;
  }
  
  .project-image img {
    width: 100%;
    border-radius: 12px;
    box-shadow: 0 6px 16px rgba(0,0,0,0.15);
    transition: transform 0.3s ease;
  }
  
  .project-image img:hover {
    transform: scale(1.05);
  }
  
  .project-links {
    margin-top: 1.2em;
    display: flex;
    gap: 15px;
    flex-wrap: wrap;
  }
  
  .project-link {
    display: inline-flex;
    align-items: center;
    gap: 8px;
    padding: 10px 20px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    text-decoration: none;
    border-radius: 8px;
    font-weight: 600;
    font-size: 0.95em;
    transition: all 0.3s ease;
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
  }
  
  .project-link:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 16px rgba(102, 126, 234, 0.6);
    color: white;
  }
  
  .publication-type {
    display: inline-block;
    padding: 6px 14px;
    background: #3498db;
    color: white;
    border-radius: 20px;
    font-size: 0.85em;
    font-weight: 600;
    margin-bottom: 0.8em;
  }
  
  .journal-badge {
    background: #27ae60;
  }
  
  .conference-badge {
    background: #e67e22;
  }
  
  .section-header {
    text-align: center;
    margin-bottom: 2em;
    color: #2c3e50;
  }
  
  @media (max-width: 768px) {
    .project-container {
      flex-direction: column;
      padding: 1.5em;
    }
    
    .project-text {
      flex: 1 1 100%;
      order: 2;
    }
    
    .project-image {
      flex: 1 1 100%;
      max-width: 100%;
      order: 1;
      margin-bottom: 1em;
    }
  }
</style>

<div class="section-header">
  <h2>ðŸ§  Research Publications</h2>
  <p>Exploring the intersection of neuroscience, machine learning, and cognitive computing</p>
</div>

---

<div class="project-container">
  <div class="project-text">
    <span class="publication-type journal-badge">ðŸ“„ Journal Article</span>
    <h4>Decoding Memory with Explainable AI: A Large-Scale EEG-Based Machine Learning Study of Encoding vs. Retrieval</h4>
    <p>
      Understanding the distinct neural signatures that differentiate memory encoding from retrieval remains a key challenge in cognitive neuroscience. This study applies machine learning to EEG data from the Penn Electrophysiology of Encoding and Retrieval Study (PEERS), involving 100 participants across over 400 sessions, to classify these cognitive states. We used Discrete Wavelet Transform (DWT) on EEG signals from six critical brain regions and evaluated seven machine learning models. Gradient Boosting emerged as the most effective classifier, achieving 81.97% accuracy and a 91.62% AUC. To interpret this performance, we applied Explainable AI (XAI) methods, specifically SHapley Additive exPlanations (SHAP). This analysis revealed that theta-band relative energy, especially in the Left and Right Anterior Superior (LAS/RAS) regions, was the most influential predictor. This study advances understanding of cognitive memory processes and supports the development of adaptive, memory-aware AI systems.
    </p>
    <div class="project-links">
      <a class="project-link" href="https://doi.org/10.1016/j.neuri.2025.100227" target="_blank" rel="noopener noreferrer">
        ðŸ“– Read Full Paper
      </a>
      <a class="project-link" href="https://doi.org/10.1016/j.neuri.2025.100227" target="_blank" rel="noopener noreferrer">
        ðŸ”— DOI Link
      </a>
    </div>
  </div>
  <div class="project-image">
    <img src="images/site-logo.png" alt="EEG Memory Encoding and Retrieval Research">
  </div>
</div>

---

<div class="project-container">
  <div class="project-text">
    <span class="publication-type conference-badge">ðŸŽ¤ Conference Paper</span>
    <h4>Spectrogram-Driven Emotion Detection from Electroencephalogram</h4>
    <p>
      Emotion detection aims to interpret emotions through data like text, voice, and physiological signals, which holds significant potential for monitoring mental health and human-computer interaction. Electroencephalogram (EEG) is a non-invasive technique recording brain activity and offers unique insights for real-time emotion detection. This study evaluates classifying emotions (positive, negative, neutral) in EEG using deep learning, emphasizing Convolutional Neural Networks (CNN). After preprocessing, time-frequency representations along with random transformations were created as inputs to the CNN architecture using short-time Fourier transform of EEG signals from the SEED dataset. The spectrograms were processed to achieve better outcomes, showing an overall accuracy of 99.80% in detecting emotion classes. The study demonstrates that processed spectrograms can be a potential field of study to recognize emotions from EEG signals.
    </p>
    <div class="project-links">
      <a class="project-link" href="https://doi.org/10.1109/ECCE64574.2025.11013815" target="_blank" rel="noopener noreferrer">
        ðŸ“– Read Full Paper
      </a>
      <a class="project-link" href="https://doi.org/10.1109/ECCE64574.2025.11013815" target="_blank" rel="noopener noreferrer">
        ðŸ”— DOI Link
      </a>
    </div>
  </div>
  <div class="project-image">
    <img src="/assets/images/project2-emotion-eeg.jpg" alt="EEG-Based Emotion Detection Research">
  </div>
</div>

---
